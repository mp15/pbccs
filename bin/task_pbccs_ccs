#!/usr/bin/env python

# TODO replace this with native C++ implementation.

"""
Wrapper for 'ccs' executable to provide tool contract interface support (and
incidentally, using DataSet XML as input).  Note that this will *not* currently
support chunking, since it access the individual .bam files en masse.
"""

import logging
import re
import os
import sys

from pbcommand.models import FileTypes, SymbolTypes, get_pbparser
from pbcommand.models.report import Report, Attribute
from pbcommand.cli import pbparser_runner
from pbcommand.utils import setup_log
from pbcommand.engine import run_cmd
from pbcore.io import SubreadSet, ConsensusReadSet

__version__ = "0.1"
log = logging.getLogger(__name__)

class Constants(object):
    TOOL_ID = "pbccs.tasks.ccs"
    TOOL_NAME = "ccs"
    DRIVER_EXE = "task_pbccs_ccs --resolved-tool-contract "
    CCS_EXE = os.environ.get("__PBTEST_CCS_EXE", "ccs")
    #
    MIN_SNR_ID = "pbccs.task_options.min_snr"
    MIN_SNR_DEFAULT = 0.00
    MIN_READ_SCORE_ID = "pbccs.task_options.min_read_score"
    MIN_READ_SCORE_DEFAULT = 0.00
    MAX_LENGTH_ID = "pbccs.task_options.max_length"
    MAX_LENGTH_DEFAULT = 7000
    MIN_LENGTH_ID = "pbccs.task_options.min_length"
    MIN_LENGTH_DEFAULT = 10
    MIN_PASSES_ID = "pbccs.task_options.min_passes"
    MIN_PASSES_DEFAULT = 3
    MIN_PREDICTED_ACCURACY_ID = "pbccs.task_options.min_predicted_accuracy"
    MIN_PREDICTED_ACCURACY_DEFAULT = 0.9
    MIN_ZSCORE_ID = "pbccs.task_options.min_zscore"
    MIN_ZSCORE_DEFAULT = "nan"
    MAX_DROP_FRAC_ID = "pbccs.task_options.max_drop_fraction"
    MAX_DROP_FRAC_DEFAULT = 0.34
    NO_POLISH_ID="pbccs.task_options.no_polish"
    NO_POLISH_DEFAULT=False
    #
    REPORT_FIELDS = {
        "CCS generated": "num_ccs_reads",
        "Below SNR threshold": "num_below_snr_threshold",
        "No usable subreads": "num_no_usable_subreads",
        "Insert size too long": "num_insert_size_too_long",
        "Insert size too small": "num_insert_size_too_small",
        "Not enough full passes": "num_not_enough_full_passes",
        "Too many unusable subreads": "num_too_many_unusable_subreads",
        "CCS did not converge": "num_not_converged",
        "CCS below minimum predicted accuracy": "num_below_min_accuracy",
    }


def args_runner(args):
    raise NotImplementedError("Please call 'ccs' directly.")


def resolved_tool_contract_runner(rtc):
    """
    Run the ccs binary from the resolved tool contract, and generate an XML
    dataset around the resulting .bam file.
    """
    ds = SubreadSet(rtc.task.input_files[0])
    output_file = rtc.task.output_files[0]
    if output_file.endswith(".consensusreadset.xml"):
        output_file = re.sub(".consensusreadset.xml", ".bam", output_file)
    assert output_file.endswith(".bam")
    report_file = rtc.task.output_files[1]
    csv_file = os.path.splitext(report_file)[0] + ".csv"
    log.info("CCS_EXE = {e}".format(e=Constants.CCS_EXE))
    args = [
        Constants.CCS_EXE,
        "--pbi",
        "--force",
        "--logLevel=DEBUG",
        "--reportFile=%s" % csv_file,
        "--numThreads=%d" % rtc.task.nproc,
        "--minSnr=%g" % rtc.task.options[Constants.MIN_SNR_ID],
        "--minReadScore=%g" % rtc.task.options[Constants.MIN_READ_SCORE_ID],
        "--maxLength=%d" % rtc.task.options[Constants.MAX_LENGTH_ID],
        "--minLength=%d" % rtc.task.options[Constants.MIN_LENGTH_ID],
        "--minPasses=%d" % rtc.task.options[Constants.MIN_PASSES_ID],
        "--minZScore=%g" % rtc.task.options[Constants.MIN_ZSCORE_ID],
        "--maxDropFraction=%g" % rtc.task.options[Constants.MAX_DROP_FRAC_ID],
        "--minPredictedAccuracy=%g" % \
            rtc.task.options[Constants.MIN_PREDICTED_ACCURACY_ID],
        "--noPolish" if rtc.task.options[Constants.NO_POLISH_ID] else "",
        output_file,
    ]
    zmwRanges = ds.zmwRanges
    if len(zmwRanges) > 0:
        movie_ids = set([m for (m, s, e) in zmwRanges])
        # XXX this restriction could go away in the future but in practice it
        # will probably always be satisfied anyway
        assert len(movie_ids) == 1, \
            "ZMW ranges restricted to a single movie at present."
        args.append("--zmws=" +
                    ",".join(["%d-%d" % (s, e) for (m, s, e) in zmwRanges]))
        # TODO let the C++ side handle some of this
        # args.append("--zmws=" + zmwRanges[0][0] + ":" +
        #            ",".join([ "%d-%d" % (s,e) for (m,s,e) in zmwRanges ]))
        # XXX hack to make sure we only pass the names of files that contain
        # reads from the specified movie
        movie_id = list(movie_ids)[0]
        for bam in ds.resourceReaders():
            for rg in bam.readGroupTable:
                if rg.MovieName == movie_id:
                    args.append(bam.filename)
                    break
    else:
        args.extend(ds.toExternalFiles())
    ds.close()
    logging.info(" ".join(args))
    result = run_cmd(
        cmd=" ".join(args),
        stdout_fh=sys.stdout,
        stderr_fh=sys.stderr)
    if result.exit_code != 0:
        return result.exit_code
    assert os.path.isfile(output_file)
    ccs = ConsensusReadSet(output_file)
    ccs.write(rtc.task.output_files[0])
    ccs.close()
    _process_csv(csv_file, report_file)
    return 0


# FIXME(nechols)(2016-01-26): this is evil
def _process_csv(csv_file, report_file):
    logging.info("reading attributes from %s" % csv_file)
    attributes = []
    with open(csv_file) as f:
        for line in f.read().splitlines():
            fields = line.strip().split(",")
            if len(fields) == 0 or fields == ['']:
                logging.critical("MISFORMED CSV LINE: {l}".format(l=line))
                break
            elif len(fields) < 2:
                logging.critical("MISFORMED CSV LINE: {l}".format(l=line))
                continue
            label = re.sub(".*\ \-\-\ ", "", fields[0])
            field_id = Constants.REPORT_FIELDS.get(label, None)
            if field_id is None:
                field_id = re.sub("\ ", "_", label.lower())
            a = Attribute(field_id, int(fields[1]), name=label)
            attributes.append(a)
    r = Report("ccs_processing", attributes=attributes)
    r.write_json(report_file)
    logging.info("wrote %s" % report_file)
    return r


def get_parser():
    p = get_pbparser(
        tool_id=Constants.TOOL_ID,
        version=__version__,
        name=Constants.TOOL_NAME,
        description=__doc__,
        driver_exe=Constants.DRIVER_EXE,
        nproc=SymbolTypes.MAX_NPROC)
    p.add_input_file_type(FileTypes.DS_SUBREADS, "subread_set",
                          "SubreadSet", "Subread DataSet or .bam file")
    p.add_output_file_type(FileTypes.DS_CCS, "bam_output",
                           name="ConsensusReadSet",
                           description="Output DataSet XML file",
                           default_name="ccs.consensusreadset.xml")
    p.add_output_file_type(FileTypes.REPORT, "report_json",
                           name="JSON report",
                           description="JSON report",
                           default_name="ccs_report.json")
    p.add_float(Constants.MIN_SNR_ID, "minSnr",
                default=Constants.MIN_SNR_DEFAULT,
                name="Minimum SNR",
                description="Minimum SNR of input subreads")
    p.add_float(Constants.MIN_READ_SCORE_ID, "minReadScore",
                default=Constants.MIN_READ_SCORE_DEFAULT,
                name="Minimum Read Score",
                description="Minimum read score of input subreads")
    p.add_int(Constants.MAX_LENGTH_ID, "maxLength",
              default=Constants.MAX_LENGTH_DEFAULT,
              name="Maximum Length",
              description="Maximum length of subreads to use for generating CCS")
    p.add_int(Constants.MIN_LENGTH_ID, "minLength",
              default=Constants.MIN_LENGTH_DEFAULT,
              name="Minimum Length",
              description="Minimum length of subreads to use for generating CCS")
    p.add_int(Constants.MIN_PASSES_ID, "minPasses",
              default=Constants.MIN_PASSES_DEFAULT,
              name="Minimum Number of Passes",
              description="Minimum number of subreads required to generate CCS")
    p.add_float(Constants.MIN_PREDICTED_ACCURACY_ID, "minPredictedAccuracy",
                default=Constants.MIN_PREDICTED_ACCURACY_DEFAULT,
                name="Minimum Predicted Accuracy",
                description="Minimum predicted accuracy in [0, 1]")
    p.add_float(Constants.MIN_ZSCORE_ID, "minZScore",
                default=Constants.MIN_ZSCORE_DEFAULT,
                name="Minimum Z Score",
                description="Minimum Z score to use a subread")
    p.add_float(Constants.MAX_DROP_FRAC_ID, "maxDropFraction",
                default=Constants.MAX_DROP_FRAC_DEFAULT,
                name="Maximum Dropped Fraction",
                description="Maximum fraction of subreads that can be dropped before " +
                "giving up")
    p.add_boolean(Constants.NO_POLISH_ID, "noPolish",
                  default=Constants.NO_POLISH_DEFAULT,
                  name="No Polish CCS",
                  description="Only output the initial template derived from the POA")
    return p


def main(argv=sys.argv):
    logging.basicConfig(level=logging.INFO)
    return pbparser_runner(
        argv=argv[1:],
        parser=get_parser(),
        args_runner_func=args_runner,
        contract_runner_func=resolved_tool_contract_runner,
        alog=log,
        setup_log_func=setup_log)

if __name__ == "__main__":
    sys.exit(main())
